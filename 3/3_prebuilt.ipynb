{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # pytorch basic package\n",
    "from torch import nn # neural net \n",
    "from torch.utils.data import DataLoader, Dataset # to work with data\n",
    "from torchvision import datasets # built-in data\n",
    "from torchvision.transforms import ToTensor # to convert nparrays/images into pytorch tensors\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from nn_utils import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0) # for reproducibility\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # set GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CIFAR100 dataset\n",
    "Let's experiment with a new dataset with many more images and more classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(training_data, batch_size=8, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = models.resnet50(weights=None)\n",
    "\n",
    "num_classes = 100\n",
    "\n",
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.fc = nn.Linear(in_features = resnet_model.fc.in_features, out_features = num_classes)\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "print(resnet_model)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet_model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for t in range(epochs):\n",
    "    print(f'EPOCH {t} --------------------')\n",
    "    train_loss = train(trainloader, resnet_model, loss, optimizer, 1000, device)\n",
    "    test_loss = test(t, testloader, resnet_model, loss, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_pretrained = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "resnet_model_pretrained.fc = nn.Linear(in_features = resnet_model_pretrained.fc.in_features, out_features = num_classes)\n",
    "resnet_model_pretrained = resnet_model_pretrained.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet_model_pretrained.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs = 15\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for t in range(epochs):\n",
    "    print(f'EPOCH {t} --------------------')\n",
    "    train_loss = train(trainloader, resnet_model_pretrained, loss, optimizer, 1000, device)\n",
    "    test_loss = test(t, testloader, resnet_model_pretrained, loss, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.GaussianBlur(kernel_size=3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test data from open datasets.\n",
    "test_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.CIFAR100(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train,\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(training_data, batch_size=8, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_pretrained = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "resnet_model_pretrained.fc = nn.Linear(in_features = resnet_model_pretrained.fc.in_features, out_features = num_classes)\n",
    "resnet_model_pretrained = resnet_model_pretrained.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet_model_pretrained.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "epochs = 15\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for t in range(epochs):\n",
    "    print(f'EPOCH {t} --------------------')\n",
    "    train_loss = train(trainloader, resnet_model_pretrained, loss, optimizer, 1000, device)\n",
    "    test_loss = test(t, testloader, resnet_model_pretrained, loss, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOMEWORK\n",
    "\n",
    "1. Try different built-in models to beat ResNet-50 in the CIFAR-100 classification task! Plot the different loss curves onto each other so that the differences are visible.\n",
    "2. Try different augmentations (less, more, tune the parameters) for the best model and see what improves the accuracy and what doesn't.\n",
    "3. Use your best model. Take 1000 random images from the test set and save the correctly predicted images into one directory and the misclassified ones into another directory. The images should have text above them with the ground truth and predicted classes (labels_map available online)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
